{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT_yIbUH46eR"
      },
      "outputs": [],
      "source": [
        "!pip install wandb torch_geometric gpytorch\n",
        "!pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3pzd4QB2XGc"
      },
      "outputs": [],
      "source": [
        "# #the four parts of the datasets in case of using the notebook from a different google drive\n",
        "# import gdown\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/1-JkyT8aKr9-eC2Pkof6D_qJdASYAXpUj?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/1-qmcIKbazhHGkb8gRFAjHxDzi0Jv33T-?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/106k3sK6wrcDzE_6ewGSUKqVD4nXlrIPE?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/10HjEkProRtYt5ROzamS7SY94JVuuBOxy?usp=sharing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxG3POBMwDib",
        "outputId": "a6a270a0-4202-4857-f967-bd0e920f2b29"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1BG5J8Wl7alFQvsw69IB037vuVXlNovFk?usp=sharing\")\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1-0eyQn2QIkkAEXsfVkQeEjYbT2Ns1NDw?usp=sharing\")\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1-UercFvWiMcQYMwqp6s5_cGoTGfYrFWE?usp=sharing\")\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/1-_74ogzMY0hAxs7U1d5yDsYV8Bqt6AdT?usp=sharing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEXNojNgaPze",
        "outputId": "3fa503b7-bfde-4dc9-8959-2cba565c7ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"./drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9AJZuhDpZnRa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\"\"\"\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html\n",
        "\"\"\"\n",
        "from torch_geometric.data  import InMemoryDataset\n",
        "\n",
        "class WeekGraphs(InMemoryDataset):\n",
        "    def __init__(self, root:str, transform=None):\n",
        "        super().__init__(root, transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'data.pt'\n",
        "\n",
        "    def process(self):\n",
        "        torch.save(self.collate(self.data_list), self.processed_paths[0])\n",
        "# dataset = WeekGraphs(\"/content/drive/MyDrive/Stock Market Prediction Graduation Project/graph_dataset_1st_year\", week_graphs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tqD5EKmOc_Fq"
      },
      "outputs": [],
      "source": [
        "all_points = []\n",
        "for i in range(1,4):\n",
        "  dataset = WeekGraphs(f\"./drive/MyDrive/bloomberg_graph_std_trick{i}\")\n",
        "  for k in range(len(dataset)):\n",
        "    all_points.append(dataset[k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KaLyYJ43zyA0"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import (\n",
        "    add_self_loops,\n",
        "    negative_sampling,\n",
        "    remove_self_loops ,\n",
        ")\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score,average_precision_score\n",
        "from sklearn.metrics import precision_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "# import networkx as nx\n",
        "import wandb\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.data import DataLoader as GraphDataLoader\n",
        "from typing import List , Dict,Tuple\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_geometric.nn as  gnn\n",
        "from torch_geometric.data  import Data\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "from torch.optim.adamw import AdamW\n",
        "import time\n",
        "from argparse import ArgumentParser\n",
        "import argparse\n",
        "import wandb\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "generator = torch.manual_seed(232)\n",
        "np.random.seed(232)\n",
        "torch.cuda.manual_seed(232)\n",
        "torch.cuda.manual_seed_all(232)\n",
        "random.seed(232)\n",
        "from gpytorch.models import ApproximateGP\n",
        "from gpytorch.variational import CholeskyVariationalDistribution\n",
        "from gpytorch.variational import VariationalStrategy\n",
        "import gpytorch\n",
        "from gpytorch.models import ExactGP\n",
        "from gpytorch.likelihoods import DirichletClassificationLikelihood, SoftmaxLikelihood\n",
        "from gpytorch.means import ConstantMean\n",
        "from gpytorch.kernels import ScaleKernel, RBFKernel, RFFKernel\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6UdRLRRgnUab"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, num_layers=2,hidden_size=64, output_size=64, num_steps =15 ):\n",
        "        super().__init__()\n",
        "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        # self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(num_steps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # h0 = torch.zeros(2, x.size(0), 100).to(device) # num_layers * num_directions, batch_size, hidden_size\n",
        "        # c0 = torch.zeros(2, x.size(0), 100).to(device)\n",
        "        x = self.batch_norm1(x)\n",
        "        out, _ = self.lstm1(x)\n",
        "        # out, _ = self.lstm2(out)\n",
        "        out = F.relu(self.fc1(out[:, -1, :]))\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zsGbydSFnH0b"
      },
      "outputs": [],
      "source": [
        "class GConv(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim:int=64, num_layers:int=2, encode:bool=False, concat_out:bool=False, msg_agg=\"gin\", device='cpu', dropout=0.2):\n",
        "\n",
        "        super(GConv,self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.gconv_layers = []\n",
        "        self.norm_layers = []\n",
        "        self.encode = encode\n",
        "        for _ in range(num_layers):\n",
        "            if msg_agg==\"transformer\":\n",
        "              self.gconv_layers.append(gnn.TransformerConv(emb_dim, emb_dim, heads=2, concat=False, dropout=dropout, add_self_loops = True).to(device)) # project=True ()\n",
        "            if msg_agg==\"gat\":\n",
        "              self.gconv_layers.append(gnn.GATConv(emb_dim, emb_dim, dropout=dropout, add_self_loops = True).to(device)) # project=True ()\n",
        "            if msg_agg==\"gin\":\n",
        "              self.gconv_layers.append(gnn.GINConv(nn.Sequential(nn.Linear(emb_dim, emb_dim), nn.PReLU())).to(device)) # project=True ()\n",
        "            if msg_agg==\"sage\":\n",
        "              self.gconv_layers.append(gnn.SAGEConv(emb_dim, emb_dim, aggr=[\"mean\", \"max\"], project=True).to(device)) # project=True ()\n",
        "\n",
        "            if self.encode:\n",
        "                self.norm_layers.append(nn.LayerNorm(emb_dim).to(device))\n",
        "        self.gconv_layers = nn.ModuleList(self.gconv_layers)\n",
        "        self.norm_layers = nn.ModuleList(self.norm_layers)\n",
        "\n",
        "        self.concat_out = concat_out\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "\n",
        "        outs = []\n",
        "        if self.encode:\n",
        "            outs.append(self.norm_layers[0](self.gconv_layers[0](x, edge_index)))\n",
        "        else:\n",
        "            outs.append(self.gconv_layers[0](x, edge_index))\n",
        "        for i in range(1,self.num_layers):\n",
        "            if self.encode:\n",
        "                outs.append(self.norm_layers[i](self.gconv_layers[i](outs[-1], edge_index)))\n",
        "            else:\n",
        "                outs.append(self.gconv_layers[i](outs[-1], edge_index))\n",
        "        if self.concat_out:\n",
        "            return torch.cat(outs, dim = -1)\n",
        "\n",
        "        return outs[-1]\n",
        "\n",
        "\n",
        "\n",
        "class NeuroStock(nn.Module):\n",
        "\n",
        "  def __init__(self,\n",
        "               num_timeseries_features=1,\n",
        "               n_companies=617,\n",
        "               company_emb_size=32,\n",
        "               node_emb_size=64,\n",
        "               article_emb_size=768,\n",
        "               n_industries=14,\n",
        "               n_gnn_layers=2,\n",
        "               gnn_msg_aggr=\"gin\",\n",
        "               use_timeseries_only=False,\n",
        "               graph_metadata:Tuple=None):\n",
        "    super(NeuroStock, self).__init__()\n",
        "    \"\"\"\n",
        "    company node representation will be a sum of its embedding and the output of the timeseries model (in this case it's an LSTM)\n",
        "    \"\"\"\n",
        "    self.num_timeseries_features = num_timeseries_features\n",
        "    self.n_companies = n_companies\n",
        "    self.company_emb_size = company_emb_size\n",
        "    self.node_emb_size = node_emb_size\n",
        "    self.article_emb_size = article_emb_size\n",
        "    self.n_industries = n_industries\n",
        "    self.gnn_msg_aggr = gnn_msg_aggr\n",
        "    self.n_gnn_layers = n_gnn_layers\n",
        "    self.use_timeseries_only = use_timeseries_only\n",
        "    self.lstm = LSTM(input_size=num_timeseries_features,  hidden_size=company_emb_size, output_size=company_emb_size).to(torch.float)\n",
        "\n",
        "    if graph_metadata is None:\n",
        "      raise(\"You need to pass HeteroData.metadata()\")\n",
        "    self.company_embedding = nn.Embedding(n_companies, company_emb_size).to(torch.float)\n",
        "    self.project_article = nn.Linear(article_emb_size, node_emb_size).to(torch.float)\n",
        "\n",
        "    # to_hetero transforms normal gnn aggregation layer to a heterogeneous aggregation layer\n",
        "    # https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_transformer.to_hetero\n",
        "    self.g_conv = gnn.to_hetero(GConv(emb_dim=node_emb_size, msg_agg=gnn_msg_aggr, num_layers=n_gnn_layers), graph_metadata).to(torch.float)\n",
        "    self.classifier = nn.Linear(node_emb_size, 2).to(torch.float)\n",
        "\n",
        "  def forward(self, hetero_x:HeteroData, return_representations=False):\n",
        "    companies_timeseries = self.lstm(hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.float))\n",
        "    if self.use_timeseries_only:\n",
        "      out = self.classifier(companies_timeseries)\n",
        "      if return_representations:\n",
        "        return out, companies_timeseries\n",
        "      return out\n",
        "\n",
        "    hetero_x[\"sentence\"].x = self.project_article(hetero_x[\"sentence\"].x.to(torch.float))\n",
        "    companies = self.company_embedding(hetero_x[\"company\"].x)\n",
        "    # print(hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.double).shape, hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.float).dtype)\n",
        "    # company_timeseries is of shape (n_companies*batch_size, n_days, n_features)  the features are \"open\", \"high\", \"low\", \"close\", \"volume\"\n",
        "    hetero_x[\"company\"].x = companies_timeseries + companies  #companies are in shape (n_companies*batch_size, node_emb_size)\n",
        "\n",
        "    for k in hetero_x.edge_index_dict.keys():\n",
        "      hetero_x[k].edge_index = hetero_x[k].edge_index.to(torch.int64)\n",
        "    graph = self.g_conv(hetero_x.x_dict, hetero_x.edge_index_dict)\n",
        "    out = self.classifier(graph[\"company\"])\n",
        "    if return_representations:\n",
        "      return out, graph[\"company\"]\n",
        "    return out\n",
        "\n",
        "  def compute_loss(self, out, target):\n",
        "    loss = F.cross_entropy(out, target)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def get_output(neurostock:NeuroStock, points:List[HeteroData]):\n",
        "  data_loader = GraphDataLoader(\n",
        "                points,\n",
        "                batch_size=1, shuffle=False)\n",
        "  neurostock.eval()\n",
        "  valid_losses = []\n",
        "  # continue\n",
        "  valid_outs = []\n",
        "  valid_targets = []\n",
        "  with torch.no_grad():\n",
        "      for i, batch  in enumerate(data_loader):\n",
        "        # if i > 2: break\n",
        "        batch = batch.to(device)\n",
        "        out = neurostock(batch)\n",
        "        # print(out.squeeze(-1).unsqueeze(0))\n",
        "        # print(batch[\"target\"].shape)\n",
        "        # break\n",
        "        valid_outs.append(out.unsqueeze(0).cpu().detach())\n",
        "        valid_targets.append(batch[\"target\"].unsqueeze(0).cpu().detach())\n",
        "        loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "        valid_losses.append(loss.item())\n",
        "  valid_outs = torch.cat(valid_outs).numpy()\n",
        "  valid_targets = torch.cat(valid_targets).numpy()\n",
        "  return valid_outs, valid_targets\n",
        "\n",
        "def get_output_representations(neurostock:NeuroStock, points:List[HeteroData]):\n",
        "  data_loader = GraphDataLoader(\n",
        "                points,\n",
        "                batch_size=1, shuffle=False)\n",
        "  neurostock.eval()\n",
        "  device = next(neurostock.parameters()).device\n",
        "  valid_losses = []\n",
        "  # continue\n",
        "  representations = []\n",
        "  targets = []\n",
        "  with torch.no_grad():\n",
        "      for i, batch  in enumerate(data_loader):\n",
        "        # if i > 2: break\n",
        "        batch = batch.to(device)\n",
        "        out = neurostock.forward(batch, return_representations=True)[1]\n",
        "        representations.append(out.cpu().detach())\n",
        "        targets.append(batch[\"target\"].cpu().detach())\n",
        "\n",
        "  representations = torch.cat(representations)\n",
        "  targets = torch.cat(targets)\n",
        "  return representations, targets\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QhZHQjRNn9g"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XYCDpaQcvmxG"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GPModel(ApproximateGP):\n",
        "    def __init__(self, num_classes, inducing_points):\n",
        "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
        "        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
        "        super(GPModel, self).__init__(variational_strategy)\n",
        "        self.mean_module = ConstantMean(batch_shape=torch.Size((num_classes,)))\n",
        "        self.covar_module = ScaleKernel(\n",
        "            RBFKernel(batch_shape=torch.Size((num_classes,))),\n",
        "            batch_shape=torch.Size((num_classes,)),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\n",
        "\n",
        "def get_gp_model(gp_train_x, gp_train_y)-> Tuple[ApproximateGP, DirichletClassificationLikelihood]:\n",
        "\n",
        "\n",
        "  inducing_points = gp_train_x[np.linspace(0, len(gp_train_x)-1, 500, dtype=int)]\n",
        "\n",
        "\n",
        "  likelihood = DirichletClassificationLikelihood(gp_train_y, learn_additional_noise=True, ).to(torch.double)\n",
        "  # likelihood.noise = torch.ones_like(likelihood.noise)\n",
        "\n",
        "  model = GPModel(likelihood.num_classes, inducing_points).to(torch.double)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      model = model.cuda()\n",
        "      likelihood = likelihood.cuda()\n",
        "  return model,  likelihood\n",
        "\n",
        "def train_gp(\n",
        "    gp:GPModel,\n",
        "    likelihood:DirichletClassificationLikelihood,\n",
        "    train_dataset:torch.utils.data.Dataset,\n",
        "    valid_x, valid_y,\n",
        "    test_x, test_y,\n",
        "    n_epochs=5, least_var_k=100)->float:\n",
        "\n",
        "  gp_optimizer = torch.optim.Adam([\n",
        "      {'params': gp.parameters()},\n",
        "      {'params': likelihood.parameters()},\n",
        "  ], lr=0.0001)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "  best_val_acc = 0\n",
        "  mll = gpytorch.mlls.VariationalELBO(likelihood, gp, num_data=len(train_dataset))\n",
        "  torch.save(gp, \"./best_gp.pt\")\n",
        "  torch.save(likelihood, \"./best_likelihood.pt\")\n",
        "  for i in tqdm(range(n_epochs)):\n",
        "      # Within each iteration, we will go over each minibatch of data\n",
        "      gp.train()\n",
        "      likelihood.train()\n",
        "\n",
        "      for x_batch, y_batch in train_loader:\n",
        "        x_batch = x_batch.to(\"cuda\").to(torch.double)\n",
        "        y_batch = y_batch.to(\"cuda\").to(torch.double)\n",
        "        gp_optimizer.zero_grad()\n",
        "\n",
        "        output = gp(x_batch)\n",
        "        loss = -mll(output, y_batch.T).sum()\n",
        "\n",
        "        loss.backward()\n",
        "        gp_optimizer.step()\n",
        "\n",
        "      gp.eval()\n",
        "      likelihood.eval()\n",
        "      lowest_var_accs = []\n",
        "      for i in range(len(valid_x)// 616):\n",
        "        with torch.no_grad():\n",
        "            test_dist = gp(valid_x[i*616: (i+1)*616].to(\"cuda\").to(torch.double))\n",
        "            pred_means = test_dist.loc.detach().cpu()\n",
        "            lower_bound, upper_bound = likelihood(test_dist).confidence_region()\n",
        "\n",
        "\n",
        "        vars = [ ]\n",
        "        for lb, ub, label in zip(lower_bound.detach().cpu().T, upper_bound.detach().cpu().T, pred_means.argmax(0)):\n",
        "          vars.append(abs(lb[label])+abs(ub[label]))\n",
        "        vars = torch.tensor(vars)\n",
        "        lowest_var_acc = (pred_means.argmax(0)[vars.argsort()[:least_var_k]] == valid_y[vars.argsort()[:least_var_k]]).numpy().mean()\n",
        "        lowest_var_accs.append(lowest_var_acc)\n",
        "      if np.mean(lowest_var_acc) > best_val_acc:\n",
        "        best_val_acc = np.mean(lowest_var_acc)\n",
        "        torch.save(gp, \"./best_gp.pt\")\n",
        "        torch.save(likelihood, \"./best_likelihood.pt\")\n",
        "\n",
        "  gp = torch.load(\"./best_gp.pt\")\n",
        "  likelihood = torch.load(\"./best_likelihood.pt\")\n",
        "  gp.eval()\n",
        "  likelihood.eval()\n",
        "  lowest_var_accs = []\n",
        "  all_vars = []\n",
        "  for i in range(len(test_x)// 616):\n",
        "    with torch.no_grad():\n",
        "        test_dist = gp(test_x[i*616: (i+1)*616].to(\"cuda\").to(torch.double))\n",
        "        pred_means = test_dist.loc.detach().cpu()\n",
        "        lower_bound, upper_bound = likelihood(test_dist).confidence_region()\n",
        "\n",
        "\n",
        "    vars = [ ]\n",
        "    for lb, ub, label in zip(lower_bound.detach().cpu().T, upper_bound.detach().cpu().T, pred_means.argmax(0)):\n",
        "      vars.append(abs(lb[label])+abs(ub[label]))\n",
        "    vars = torch.tensor(vars)\n",
        "    all_vars.append(vars[vars.argsort()[:least_var_k]])\n",
        "    lowest_var_acc = (pred_means.argmax(0)[vars.argsort()[:least_var_k]] == test_y[vars.argsort()[:least_var_k]]).numpy().mean()\n",
        "    lowest_var_accs.append(lowest_var_acc)\n",
        "\n",
        "  return np.mean(lowest_var_accs), torch.cat(all_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2WrZxQwMPG5f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"]=\"4d60aa176a9e71fedbbaddb7ea594784ac8cc1ad\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_FEnddZRyPu",
        "outputId": "5259764b-c5eb-4e6a-80d0-c2c1e0f623f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmirette-gp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iQ1oOmvMYCs"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import wandb\n",
        "\n",
        "\"\"\"\n",
        "file_path_in_run username/project/run_id\n",
        "\"\"\"\n",
        "\n",
        "def restore_file_wandb(file_path:str, run_name:str):\n",
        "    # if not os.path.exists(\"/\".join(file_path.split(\"/\")[:-1])):\n",
        "    #     os.makedirs(\"/\".join(file_path.split(\"/\")[:-1]))\n",
        "    wandb.restore(file_path, run_path=run_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie65Gg6x2I3R"
      },
      "outputs": [],
      "source": [
        "restore_file_wandb(\"neurostock_lstm.pt\", \"mirette-gp/bloomberg_graph/6dsvbqqd\")\n",
        "restore_file_wandb(\"neurostock_gnn.pt\", \"mirette-gp/bloomberg_graph/915dbdpv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "kU-Cj-HQbE6_",
        "outputId": "cc3f68c2-8314-430b-800f-2a41711ee096"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmirette-gp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230627_214135-bmbw2rw5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mirette-gp/bloomberg_graph_stdLabel_simple_train/runs/bmbw2rw5' target=\"_blank\">lstm_companies_k100</a></strong> to <a href='https://wandb.ai/mirette-gp/bloomberg_graph_stdLabel_simple_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mirette-gp/bloomberg_graph_stdLabel_simple_train' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph_stdLabel_simple_train</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mirette-gp/bloomberg_graph_stdLabel_simple_train/runs/bmbw2rw5' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph_stdLabel_simple_train/runs/bmbw2rw5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [11:53<00:00,  7.14s/it]\n",
            "100%|██████████| 40/40 [04:08<00:00,  6.22s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "train_config = {\n",
        "  \"n_epochs\" : 100,\n",
        "  \"node_emb_size\" : 128,\n",
        "  \"lr\" : 0.001,\n",
        "  \"weight_decay\" : 0.01,\n",
        "  \"step_size\" : 7,\n",
        "  \"start_day\" : 500,\n",
        "  \"train_size\" : 600,\n",
        "  \"test_interval\" : 100,\n",
        "  \"train_batch_size\": 4,\n",
        "  \"use_timeseries_only\": True,\n",
        "  \"reset_parameters\" : False,\n",
        "  \"reset_parameters_freq\" : 5,\n",
        "  \"gnn_msg_aggr\": \"gin\",  # can be gin sage gat transformer\n",
        "  \"highest_conf_k\" : 100,\n",
        "  \"model_file_name\" : \"./neurostock_lstm.pt\",\n",
        "  \"run_name\" : \"lstm_companies_k100\",\n",
        "  \"project_name\":  \"bloomberg_graph_stdLabel_simple_train\",\n",
        "  \"wandb_mode\" : \"online\",\n",
        "  \"gp_train_days\" : 100,\n",
        "  \"gp_val_days\" : 20,\n",
        "  \"gp_epochs\" : 40,\n",
        "}\n",
        "wandb.finish()\n",
        "wandb.init(\n",
        "    project=train_config[\"project_name\"],\n",
        "    name=train_config[\"run_name\"],\n",
        "    config=train_config,\n",
        "    mode=train_config[\"wandb_mode\"])\n",
        "# warmup_steps=\n",
        "neurostock = NeuroStock(\n",
        "    node_emb_size=train_config[\"node_emb_size\"],\n",
        "    company_emb_size=train_config[\"node_emb_size\"],\n",
        "    gnn_msg_aggr=train_config[\"gnn_msg_aggr\"],\n",
        "    use_timeseries_only=train_config[\"use_timeseries_only\"],\n",
        "    graph_metadata=all_points[0].metadata())\n",
        "\n",
        "neurostock.to('cuda')\n",
        "device = next(neurostock.parameters()).device\n",
        "optimizer =  torch.optim.AdamW(neurostock.parameters(),\n",
        "                               lr=train_config[\"lr\"],\n",
        "                               weight_decay=train_config[\"weight_decay\"] )\n",
        "accs = []\n",
        "accum_companies = []\n",
        "gp_accs = []\n",
        "gp_vars = []\n",
        "# lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1,  total_iters=warmup_steps)\n",
        "\n",
        "# if train_config[\"reset_parameters\"] and (split_index + 1) % train_config[\"reset_parameters_freq\"]  == 0 :\n",
        "#   for layer in neurostock.children():\n",
        "#     if hasattr(layer, 'reset_parameters'):\n",
        "#         layer.reset_parameters()\n",
        "\n",
        "train_loader = GraphDataLoader(\n",
        "    all_points[train_config[\"start_day\"]:train_config[\"start_day\"]+train_config[\"train_size\"]],\n",
        "    batch_size=train_config[\"train_batch_size\"], shuffle=True)\n",
        "test_loader = GraphDataLoader(\n",
        "    all_points[train_config[\"start_day\"]+train_config[\"train_size\"]:train_config[\"start_day\"]+train_config[\"train_size\"]+train_config[\"test_interval\"]],\n",
        "    batch_size=1, shuffle=False)\n",
        "best_val_acc = 0\n",
        "for e in tqdm(range(train_config[\"n_epochs\"])):\n",
        "    train_losses= []\n",
        "    neurostock.train()\n",
        "    train_outs = []\n",
        "    train_targets = []\n",
        "    for batch  in train_loader:\n",
        "        # with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "        # with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "        batch = batch.to(device)\n",
        "        out = neurostock(batch)\n",
        "        train_outs.append(out.cpu().detach().unsqueeze(0))\n",
        "        train_targets.append(batch[\"target\"].cpu().detach().unsqueeze(0))\n",
        "        loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "        optimizer.zero_grad()\n",
        "        train_losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # lr_scheduler.step()\n",
        "\n",
        "    neurostock.eval()\n",
        "    valid_losses = []\n",
        "    # continue\n",
        "    valid_outs = []\n",
        "    valid_targets = []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch  in enumerate(test_loader):\n",
        "          batch = batch.to(device)\n",
        "          out = neurostock(batch)\n",
        "          valid_outs.append(out.cpu().detach().unsqueeze(0))\n",
        "          valid_targets.append(batch[\"target\"].cpu().detach().unsqueeze(0))\n",
        "          loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "          valid_losses.append(loss.item())\n",
        "\n",
        "    valid_outs = torch.cat(valid_outs).numpy()\n",
        "    valid_targets = torch.cat(valid_targets).numpy()\n",
        "    acc_per_company = (valid_outs.argmax(-1) == valid_targets).mean(axis=0)\n",
        "    high_acc_companies = np.where(acc_per_company >= 0.7)[0]\n",
        "\n",
        "    valid_acc = (valid_outs.argmax(-1) == valid_targets).mean()\n",
        "    train_outs = torch.cat(train_outs).numpy()\n",
        "    train_targets = torch.cat(train_targets).numpy()\n",
        "    train_acc = (train_outs.argmax(-1) == train_targets).mean()\n",
        "    high_confidence_accs = []\n",
        "    for out, target in zip(valid_outs, valid_targets):\n",
        "      predicted_label = out.argmax(-1)\n",
        "      confidence = out.max(-1)\n",
        "      predicted_label = predicted_label[confidence.argsort()[-train_config[\"highest_conf_k\"]:]]\n",
        "      target = target[confidence.argsort()[-train_config[\"highest_conf_k\"]:]]\n",
        "      high_confidence_accs.append((target ==predicted_label).mean())\n",
        "\n",
        "    wandb.log({\n",
        "        \"train_loss\" : np.mean(train_losses),\n",
        "        \"valid_loss\" : np.mean(valid_losses),\n",
        "        \"valid_acc\" : valid_acc,\n",
        "        \"high_confidence_acc\" : np.mean(high_confidence_accs),\n",
        "        \"valid_n_high\" : (acc_per_company >= 0.7).sum(),\n",
        "        \"train_acc\" : train_acc,\n",
        "    })\n",
        "    if np.mean(high_confidence_accs) > best_val_acc :\n",
        "      best_val_acc = np.mean(high_confidence_accs)\n",
        "      torch.save(neurostock, train_config[\"model_file_name\"])\n",
        "\n",
        "neurostock = torch.load(train_config[\"model_file_name\"])\n",
        "representations, target = get_output_representations(neurostock,\n",
        "                                                      all_points[train_config[\"start_day\"]+train_config[\"train_size\"]:])\n",
        "\n",
        "gp_train_x, gp_train_y = representations[:train_config[\"gp_train_days\"]*616], target[:train_config[\"gp_train_days\"]*616]\n",
        "gp_valid_x, gp_valid_y = gp_train_x[-train_config[\"gp_val_days\"]*616:], gp_train_y[-train_config[\"gp_val_days\"]*616:]\n",
        "gp_train_x, gp_train_y = gp_train_x[:-train_config[\"gp_val_days\"]*616], gp_train_y[:-train_config[\"gp_val_days\"]*616]\n",
        "\n",
        "gp_test_x, gp_test_y = representations[train_config[\"gp_train_days\"]*616:], target[train_config[\"gp_train_days\"]*616:]\n",
        "gp_model, likelihood = get_gp_model(gp_train_x, gp_train_y)\n",
        "train_dataset = TensorDataset(gp_train_x, likelihood.transformed_targets.T)\n",
        "\n",
        "gp_uncertainty_acc, gp_vars = train_gp(gp_model, likelihood, train_dataset, gp_valid_x, gp_valid_y, gp_test_x, gp_test_y, n_epochs=train_config[\"gp_epochs\"], least_var_k=train_config[\"highest_conf_k\"])\n",
        "\n",
        "\n",
        "# wandb.finish()\n",
        "\n",
        "long_range_outputs, long_range_true = get_output(neurostock, all_points[train_config[\"start_day\"]+train_config[\"train_size\"]+train_config[\"test_interval\"]:])\n",
        "\n",
        "for out, target in zip(long_range_outputs, long_range_true):\n",
        "  predicted_label = out.argmax(-1)\n",
        "  confidence = out.max(-1)\n",
        "  predicted_label = predicted_label[confidence.argsort()[-train_config[\"highest_conf_k\"]:]]\n",
        "  target = target[confidence.argsort()[-train_config[\"highest_conf_k\"]:]]\n",
        "  high_confidence_accs.append((target ==predicted_label).mean())\n",
        "\n",
        "\n",
        "torch.save(neurostock, train_config[\"model_file_name\"])\n",
        "wandb.save(train_config[\"model_file_name\"])\n",
        "torch.save(optimizer.state_dict(),\"./neurostock_optimizer_state_dict.pt\")\n",
        "wandb.save(\"./neurostock_optimizer_state_dict.pt\")\n",
        "wandb.save(\"./best_gp.pt\")\n",
        "wandb.save(\"./best_likelihoood.pt\")\n",
        "\n",
        "wandb.log({\n",
        "           \"long_range_acc\" : (long_range_outputs.argmax(-1) == long_range_true).mean(),\n",
        "           \"long_range_conf_ac\" : np.mean(high_confidence_accs),\n",
        "           \"gp_uncertainty_split_acc\": gp_uncertainty_acc,\n",
        "           })\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "352fb8f1cda14da5bb760a21f70dfeae",
            "19a61040518445469108bdc2bd090e7e",
            "56c5cd72448d41e689698bde45b4dced",
            "eb9da3a615334a0b8eec53b9df59ae95",
            "fb59187e04ad42b59180a87cd35b2c0d",
            "1e6ded48ca4f472f9565528dfc75f432",
            "bd27f5f00116474fadcec5763f9e9b49",
            "1ec7addb55a74073a8a13d754908cff3"
          ]
        },
        "id": "XaJSUav3rFxI",
        "outputId": "820bddbc-5afa-4c3c-de9b-be9fb9d90c36"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230627_122801-4df1bxtm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/4df1bxtm' target=\"_blank\">gnn_gp_benchmark_rbf_K10_companies_3_val_days</a></strong> to <a href='https://wandb.ai/mirette-gp/bloomberg_graph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mirette-gp/bloomberg_graph' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/4df1bxtm' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph/runs/4df1bxtm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.31s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.32s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.38s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.36s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.36s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.37s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.34s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "1it [00:19, 19.33s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.29s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.42s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.27s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.26s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.27s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.41s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.41s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "2it [00:38, 19.46s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.41s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.34s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.27s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.27s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.35s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.33s/it]\n",
            "3it [00:58, 19.41s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.30s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.21s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.27s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.32s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:04,  1.33s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.34s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.35s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.33s/it]\n",
            "4it [01:17, 19.27s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.15s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.20s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.37s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.50s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.40s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.36s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "5it [01:36, 19.23s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.23s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.41s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.27s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.27s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.26s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.26s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n",
            "6it [01:55, 19.16s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.43s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.38s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.41s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.32s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.30s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.28s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.29s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n",
            "7it [02:14, 19.21s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.42s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.34s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.27s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.32s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.34s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
            "8it [02:34, 19.22s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.24s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.31s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.55s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.44s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.36s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.31s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "9it [02:53, 19.23s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.34s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.49s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.27s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.27s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.27s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.26s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.26s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n",
            "10it [03:12, 19.23s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.62s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.52s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.41s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.32s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.30s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.31s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.33s/it]\n",
            "11it [03:32, 19.39s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.51s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.44s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.34s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.35s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.37s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.37s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.34s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "12it [03:51, 19.49s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.36s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.47s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.33s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.29s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.28s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.27s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.27s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n",
            "13it [04:11, 19.44s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.49s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.55s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.29s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.28s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.27s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.27s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n",
            "14it [04:30, 19.50s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.63s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.50s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.27s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.27s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.32s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.34s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.35s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "15it [04:50, 19.57s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.34s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.39s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.38s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.38s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.37s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.40s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.35s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "16it [05:10, 19.56s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.43s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.55s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.29s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.29s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.29s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n",
            "17it [05:29, 19.52s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.57s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.56s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.41s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.36s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.34s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "18it [05:49, 19.64s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.58s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.46s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.32s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.34s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.34s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
            "19it [06:09, 19.60s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.33s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.40s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.60s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.43s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.37s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.34s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "20it [06:28, 19.59s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.42s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.53s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.29s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.28s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.28s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n",
            "21it [06:48, 19.62s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.69s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.54s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.30s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.31s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:04,  1.33s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.37s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.36s/it]\n",
            "22it [07:08, 19.72s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.36s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.38s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.40s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.41s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.40s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.36s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.38s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
            "23it [07:27, 19.70s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.32s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.50s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.29s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.29s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.29s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.30s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.29s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n",
            "24it [07:47, 19.61s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.52s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.50s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.29s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.28s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.37s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.36s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "25it [08:07, 19.66s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.59s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.48s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.29s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.34s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.38s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.38s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.39s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.36s/it]\n",
            "26it [08:26, 19.69s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.35s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.40s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.40s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.36s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.38s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.31s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.33s/it]\n",
            "27it [08:46, 19.60s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.47s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.60s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.28s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.28s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.27s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.27s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n",
            "28it [09:05, 19.57s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.60s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.46s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.29s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.28s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.36s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.36s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.36s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "29it [09:25, 19.62s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.43s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.38s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.37s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.36s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.37s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.33s/it]\n",
            "30it [09:44, 19.56s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.31s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.44s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.33s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.44s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.38s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.33s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "31it [10:04, 19.59s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.53s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.53s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.29s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.29s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.29s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.28s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.30s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n",
            "32it [10:24, 19.59s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.58s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.47s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.42s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.40s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.39s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.38s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.38s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
            "33it [10:43, 19.65s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.31s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.39s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.41s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.40s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.36s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "34it [11:03, 19.65s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.40s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.57s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.31s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.30s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.29s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.30s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n",
            "35it [11:23, 19.62s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.65s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.49s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.32s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.30s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.34s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.38s/it]\n",
            "36it [11:43, 19.72s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.46s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.42s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.40s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.39s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.41s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.39s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.36s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
            "37it [12:02, 19.70s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.36s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.49s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.36s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.33s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.32s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.37s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.34s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "38it [12:22, 19.71s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.65s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.68s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.32s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.30s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.30s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.31s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
            "39it [12:42, 19.80s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.70s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.57s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.31s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.45s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.42s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.42s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:07<00:01,  1.43s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.40s/it]\n",
            "40it [13:02, 19.93s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.46s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.55s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.41s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.37s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.34s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.32s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.31s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.33s/it]\n",
            "41it [13:22, 19.88s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.56s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.67s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.52s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.39s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.35s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.34s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.33s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "42it [13:42, 19.97s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.86s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.69s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.31s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.31s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.35s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.37s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:07<00:01,  1.45s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.40s/it]\n",
            "43it [14:03, 20.10s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.50s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.54s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.41s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.41s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.37s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.34s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.33s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "44it [14:22, 20.01s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.50s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.69s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.31s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.36s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
            "45it [14:42, 19.98s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.84s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.66s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.31s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.30s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.35s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "46it [15:02, 20.01s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.59s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.53s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.40s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.38s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.48s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.43s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.37s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.38s/it]\n",
            "47it [15:22, 19.99s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.42s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.58s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.33s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.31s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.30s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.30s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.29s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n",
            "48it [15:42, 19.91s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.62s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.63s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.30s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.37s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.34s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.32s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
            "49it [16:02, 19.94s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.69s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.56s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.31s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.36s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.37s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.38s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.39s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
            "50it [16:22, 20.01s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.40s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.50s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:07,  1.40s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.37s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:03,  1.33s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.31s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.31s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
            "51it [16:42, 19.88s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.46s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.60s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.31s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.30s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.30s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.30s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
            "52it [17:02, 19.85s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.75s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.57s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.30s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.29s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.32s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.36s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "53it [17:21, 19.87s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.41s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.40s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.39s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.38s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.38s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.42s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.37s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
            "54it [17:41, 19.81s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.35s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.48s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.31s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:03,  1.29s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.28s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n",
            "55it [18:01, 19.68s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.48s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.52s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.28s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:04,  1.34s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.31s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.30s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
            "56it [18:20, 19.67s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.54s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.43s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.29s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.31s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:03<00:04,  1.34s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.36s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n",
            "57it [18:40, 19.64s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:05<00:05,  5.30s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.36s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:06,  1.39s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:05,  1.41s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:04<00:04,  1.45s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.39s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.36s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.38s/it]\n",
            "58it [18:59, 19.65s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "352fb8f1cda14da5bb760a21f70dfeae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='6.878 MB of 11.667 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.58957…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_acc</td><td>▁</td></tr><tr><td>avg_gp_acc</td><td>▁</td></tr><tr><td>avg_high_company_occurrence</td><td>▁</td></tr><tr><td>gp_uncertainty_split_acc</td><td>▅▅▅▆▅▄▂▆▃▄▂█▅▆▇▄▅▄▂▅▄▅▅▇▆▁▄▂▆▇▄▇▅▄▅▆▅▅▅▁</td></tr><tr><td>high_conf_acc_std</td><td>▁</td></tr><tr><td>high_conf_avgs</td><td>▁</td></tr><tr><td>high_confidence_acc</td><td>▅▆█████▇█▆▃▇▃▂▇▂▃▅▂▂▁▂▅▃▅▂▂▄▆▂▆▄▃▅▅▃▄▃▃▃</td></tr><tr><td>higher_0.7_mean</td><td>▁</td></tr><tr><td>higher_0.7_std</td><td>▁</td></tr><tr><td>long_range_acc</td><td>▁</td></tr><tr><td>std_gp_acc</td><td>▁</td></tr><tr><td>train_acc</td><td>▄▅▆▇▇██▇█▇█▇▇▅▆▃▆▅▅▅▅▅▃▄▃▄▅▄▄▄▄▅▄▄▃▃▁▄▅▃</td></tr><tr><td>train_loss</td><td>▅▂▁▁▁▁▁▂▁▂▂▂▂▄▃█▃▄▄▃▄▄▅▆▅▅▅▅▅▆▆▅▅▅▇▆█▆▅▆</td></tr><tr><td>valid_acc</td><td>▄█▅▅▅▇▄▅▃▄▃▅▃▂▃▄▃▆▃▁▄▃▃▃▄▅▃▇▇▄▆▅▂▃▂▅█▄▂▂</td></tr><tr><td>valid_loss</td><td>▄▃▃▄▃▁▃▃▄▄▅▇▅▆▇▆▅▃▆█▅▅▅▅▅▅▅▄▄▅▄▅█▆▆▅▄▇▇▆</td></tr><tr><td>valid_n_high</td><td>▃▇▃▄▃█▃▅▅▃▃▃▂▁▃▄▃▅▂▂▃▄▂▂▄▄▃▆▆▅▅▅▄▂▂▄█▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_acc</td><td>0.51657</td></tr><tr><td>avg_gp_acc</td><td>0.48916</td></tr><tr><td>avg_high_company_occurrence</td><td>47.4</td></tr><tr><td>gp_uncertainty_split_acc</td><td>0.0</td></tr><tr><td>high_conf_acc_std</td><td>0.18677</td></tr><tr><td>high_conf_avgs</td><td>0.6633</td></tr><tr><td>high_confidence_acc</td><td>0.57143</td></tr><tr><td>higher_0.7_mean</td><td>150.93103</td></tr><tr><td>higher_0.7_std</td><td>33.66973</td></tr><tr><td>long_range_acc</td><td>0.52853</td></tr><tr><td>std_gp_acc</td><td>0.25284</td></tr><tr><td>train_acc</td><td>0.53089</td></tr><tr><td>train_loss</td><td>0.68811</td></tr><tr><td>valid_acc</td><td>0.49049</td></tr><tr><td>valid_loss</td><td>0.70175</td></tr><tr><td>valid_n_high</td><td>98</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gnn_gp_benchmark_rbf_K10_companies_3_val_days</strong> at: <a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/4df1bxtm' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph/runs/4df1bxtm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230627_122801-4df1bxtm/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "train_config = {\n",
        "  \"n_epochs\" : 2,\n",
        "  \"node_emb_size\" : 128,\n",
        "  \"lr\" : 0.001,\n",
        "  \"weight_decay\" : 0.01,\n",
        "  \"step_size\" : 7,\n",
        "  \"start_day\" : 500,\n",
        "  \"train_size\" : 300,\n",
        "  \"test_interval\" : 400,\n",
        "  \"train_batch_size\": 2,\n",
        "  \"use_timeseries_only\": False,\n",
        "  \"reset_parameters\" : False,\n",
        "  \"reset_parameters_freq\" : 5,\n",
        "  \"highest_conf_k\" : 10,\n",
        "  \"model_file_name\" : \"./neurostock_gnn.pt\",\n",
        "  \"run_name\" : \"gnn_gp_benchmark_rbf_K10_companies_3_val_days\",\n",
        "  \"project_name\":  \"bloomberg_graph\",\n",
        "  \"wandb_mode\" : \"online\",\n",
        "  \"gp_train_days\" : 20,\n",
        "  \"gp_val_days\" : 3,\n",
        "  \"gp_epochs\" : 6,\n",
        "}\n",
        "wandb.finish()\n",
        "wandb.init(\n",
        "    project=train_config[\"project_name\"],\n",
        "    name=train_config[\"run_name\"],\n",
        "    config=train_config,\n",
        "    mode=train_config[\"wandb_mode\"])\n",
        "# warmup_steps=\n",
        "neurostock = NeuroStock(\n",
        "    node_emb_size=train_config[\"node_emb_size\"],\n",
        "    company_emb_size=train_config[\"node_emb_size\"],\n",
        "    use_timeseries_only=train_config[\"use_timeseries_only\"],\n",
        "    graph_metadata=all_points[0].metadata())\n",
        "\n",
        "neurostock.to('cuda')\n",
        "device = next(neurostock.parameters()).device\n",
        "optimizer =  torch.optim.AdamW(neurostock.parameters(),\n",
        "                               lr=train_config[\"lr\"],\n",
        "                               weight_decay=train_config[\"weight_decay\"] )\n",
        "accs = []\n",
        "accum_companies = []\n",
        "high_conf_avgs = []\n",
        "gp_accs = []\n",
        "gp_vars = []\n",
        "# lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1,  total_iters=warmup_steps)\n",
        "for split_index, split in tqdm(enumerate(range(0, train_config[\"test_interval\"], train_config[\"step_size\"]))):\n",
        "\n",
        "  if train_config[\"reset_parameters\"] and (split_index + 1) % train_config[\"reset_parameters_freq\"]  == 0 :\n",
        "    for layer in neurostock.children():\n",
        "      if hasattr(layer, 'reset_parameters'):\n",
        "          layer.reset_parameters()\n",
        "\n",
        "  train_loader = GraphDataLoader(\n",
        "      all_points[train_config[\"start_day\"]+split:train_config[\"start_day\"]+split+train_config[\"train_size\"]],\n",
        "      batch_size=train_config[\"train_batch_size\"], shuffle=True)\n",
        "  test_loader = GraphDataLoader(\n",
        "      all_points[train_config[\"start_day\"]+split+train_config[\"train_size\"]:train_config[\"start_day\"]+split+train_config[\"train_size\"]+train_config[\"step_size\"]],\n",
        "      batch_size=1, shuffle=False)\n",
        "\n",
        "  for e in tqdm(range(train_config[\"n_epochs\"])):\n",
        "      train_losses= []\n",
        "      neurostock.train()\n",
        "      train_outs = []\n",
        "      train_targets = []\n",
        "      for batch  in train_loader:\n",
        "          # with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "          # with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "          batch = batch.to(device)\n",
        "          out = neurostock(batch)\n",
        "          train_outs.append(out.cpu().detach().unsqueeze(0))\n",
        "          train_targets.append(batch[\"target\"].cpu().detach().unsqueeze(0))\n",
        "          loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "          optimizer.zero_grad()\n",
        "          train_losses.append(loss.item())\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          # lr_scheduler.step()\n",
        "\n",
        "      neurostock.eval()\n",
        "      valid_losses = []\n",
        "      # continue\n",
        "      valid_outs = []\n",
        "      valid_targets = []\n",
        "      with torch.no_grad():\n",
        "\n",
        "          for i, batch  in enumerate(test_loader):\n",
        "            # if i > 2: break\n",
        "\n",
        "            batch = batch.to(device)\n",
        "            out = neurostock(batch)\n",
        "            valid_outs.append(out.cpu().detach().unsqueeze(0))\n",
        "            valid_targets.append(batch[\"target\"].cpu().detach().unsqueeze(0))\n",
        "            loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "      valid_outs = torch.cat(valid_outs).numpy()\n",
        "      valid_targets = torch.cat(valid_targets).numpy()\n",
        "      acc_per_company = (valid_outs.argmax(-1) == valid_targets).mean(axis=0)\n",
        "      high_acc_companies = np.where(acc_per_company >= 0.7)[0]\n",
        "\n",
        "      valid_acc = (valid_outs.argmax(-1) == valid_targets).mean()\n",
        "      train_outs = torch.cat(train_outs).numpy()\n",
        "      train_targets = torch.cat(train_targets).numpy()\n",
        "      train_acc = (train_outs.argmax(-1) == train_targets).mean()\n",
        "      # if e == (n_epochs- 1) :\n",
        "  representations, target = get_output_representations(neurostock,\n",
        "                                                       all_points[train_config[\"start_day\"]+split+train_config[\"train_size\"]-train_config[\"gp_train_days\"]:train_config[\"start_day\"]+split+train_config[\"train_size\"]+train_config[\"step_size\"]])\n",
        "\n",
        "  gp_train_x, gp_train_y = representations[:train_config[\"gp_train_days\"]*616], target[:train_config[\"gp_train_days\"]*616]\n",
        "  gp_valid_x, gp_valid_y = gp_train_x[-train_config[\"gp_val_days\"]*616:], gp_train_y[-train_config[\"gp_val_days\"]*616:]\n",
        "  gp_train_x, gp_train_y = gp_train_x[:-train_config[\"gp_val_days\"]*616], gp_train_y[:-train_config[\"gp_val_days\"]*616]\n",
        "\n",
        "  gp_test_x, gp_test_y = representations[train_config[\"gp_train_days\"]*616:], target[train_config[\"gp_train_days\"]*616:]\n",
        "  gp_model, likelihood = get_gp_model(gp_train_x, gp_train_y)\n",
        "  train_dataset = TensorDataset(gp_train_x, likelihood.transformed_targets.T)\n",
        "\n",
        "  gp_uncertainty_acc, vars = train_gp(gp_model, likelihood, train_dataset, gp_valid_x, gp_valid_y, gp_test_x, gp_test_y, n_epochs=train_config[\"gp_epochs\"], least_var_k=train_config[\"highest_conf_k\"])\n",
        "\n",
        "  high_confidence_accs = []\n",
        "  for out, target in zip(valid_outs, valid_targets):\n",
        "    predicted_label = out.argmax(-1)\n",
        "    confidence = out.max(-1)\n",
        "    predicted_label = predicted_label[confidence.argsort()[-train_config[\"highest_conf_k\"]:]]\n",
        "    target = target[confidence.argsort()[-train_config[\"highest_conf_k\"]:]]\n",
        "    high_confidence_accs.append((target ==predicted_label).mean())\n",
        "  high_conf_avgs.append(sum(high_confidence_accs)/len(high_confidence_accs))\n",
        "\n",
        "  wandb.log({\n",
        "          \"train_loss\" : np.mean(train_losses),\n",
        "          \"valid_loss\" : np.mean(valid_losses),\n",
        "          \"valid_acc\" : valid_acc,\n",
        "          \"high_confidence_acc\" : sum(high_confidence_accs)/len(high_confidence_accs),\n",
        "          \"valid_n_high\" : (acc_per_company >= 0.7).sum(),\n",
        "          \"train_acc\" : train_acc,\n",
        "          \"gp_uncertainty_split_acc\": gp_uncertainty_acc,\n",
        "    })\n",
        "  gp_accs.append(gp_uncertainty_acc)\n",
        "  gp_vars.append(vars.unsqueeze(0))\n",
        "  accs.append(valid_acc)\n",
        "  accum_companies.append(high_acc_companies)\n",
        "# wandb.finish()\n",
        "\n",
        "long_range_outputs, long_range_true = get_output(neurostock, all_points[train_config[\"start_day\"]+split+train_config[\"train_size\"]+train_config[\"step_size\"]:])\n",
        "\n",
        "all_high = []\n",
        "for k in  accum_companies:\n",
        "  all_high.extend(k)\n",
        "\n",
        "torch.save(neurostock, train_config[\"model_file_name\"])\n",
        "wandb.save(train_config[\"model_file_name\"])\n",
        "torch.save(optimizer.state_dict(),\"./neurostock_optimizer_state_dict.pt\")\n",
        "wandb.save(\"./neurostock_optimizer_state_dict.pt\")\n",
        "gp_vars = torch.cat(gp_vars)\n",
        "\n",
        "wandb.log({\"avg_acc\": np.mean(accs),\n",
        "           \"high_conf_avgs\" : np.mean(high_conf_avgs),\n",
        "           \"high_conf_acc_std\" : np.std(high_conf_avgs),\n",
        "           \"higher_0.7_mean\": np.mean([len(h) for h in accum_companies]),\n",
        "           \"higher_0.7_std\": np.std([len(h) for h in accum_companies]),\n",
        "           \"avg_high_company_occurrence\": np.mean(pd.Series(all_high).value_counts()[:train_config[\"highest_conf_k\"]].values),\n",
        "           \"long_range_acc\" : (long_range_outputs.argmax(-1) == long_range_true).mean(),\n",
        "           \"avg_gp_acc\" : np.mean(gp_accs),\n",
        "           \"std_gp_acc\" : np.std(gp_accs),\n",
        "           })\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYSEqzLSlVxM",
        "outputId": "13266c14-2d06-44ac-cdb8-1ec6af237a1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.83s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.724"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# just for testing #######################################\n",
        "# gp_optimizer = torch.optim.Adam([\n",
        "#       {'params': gp_model.parameters()},\n",
        "#       {'params': likelihood.parameters()},\n",
        "#   ], lr=0.01)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "# mll = gpytorch.mlls.VariationalELBO(likelihood, gp_model, num_data=len(train_dataset))\n",
        "# num_epochs = 5\n",
        "# for i in tqdm(range(num_epochs)):\n",
        "#     # Within each iteration, we will go over each minibatch of data\n",
        "#     gp_model.train()\n",
        "#     likelihood.train()\n",
        "\n",
        "#     for x_batch, y_batch in train_loader:\n",
        "#         x_batch = x_batch.to(\"cuda\").to(torch.float32)\n",
        "#         y_batch = y_batch.to(\"cuda\").to(torch.float32)\n",
        "#         gp_optimizer.zero_grad()\n",
        "\n",
        "#         output = gp_model(x_batch)\n",
        "#         # print(output.shape)\n",
        "#         # print(y_batch.shape)\n",
        "#         loss = -mll(output, y_batch.T)\n",
        "#         loss = loss.sum()\n",
        "#         loss.backward()\n",
        "#         gp_optimizer.step()\n",
        "\n",
        "\n",
        "# gp_model.eval()\n",
        "# likelihood.eval()\n",
        "# lowest_var_accs = []\n",
        "# for i in range(len(gp_test_x)// 616):\n",
        "#   with torch.no_grad():\n",
        "#       test_dist = gp_model(gp_test_x[i*616: (i+1)*616].to(\"cuda\").to(torch.double))\n",
        "#       pred_means = test_dist.loc.detach().cpu()\n",
        "#       lower_bound, upper_bound = likelihood(test_dist).confidence_region()\n",
        "\n",
        "\n",
        "#   vars = [ ]\n",
        "#   for lb, ub, label in zip(lower_bound.detach().cpu().T, upper_bound.detach().cpu().T, pred_means.argmax(0)):\n",
        "#     vars.append(abs(lb[label])+abs(ub[label]))\n",
        "#   vars = torch.tensor(vars)\n",
        "#   lowest_var_acc = (pred_means.argmax(0)[vars.argsort()[:100]] == gp_test_y[vars.argsort()[:100]]).numpy().mean()\n",
        "#   lowest_var_accs.append(lowest_var_acc)\n",
        "# np.mean(lowest_var_accs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19a61040518445469108bdc2bd090e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb59187e04ad42b59180a87cd35b2c0d",
            "placeholder": "​",
            "style": "IPY_MODEL_1e6ded48ca4f472f9565528dfc75f432",
            "value": "11.668 MB of 11.668 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "1e6ded48ca4f472f9565528dfc75f432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ec7addb55a74073a8a13d754908cff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "352fb8f1cda14da5bb760a21f70dfeae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19a61040518445469108bdc2bd090e7e",
              "IPY_MODEL_56c5cd72448d41e689698bde45b4dced"
            ],
            "layout": "IPY_MODEL_eb9da3a615334a0b8eec53b9df59ae95"
          }
        },
        "56c5cd72448d41e689698bde45b4dced": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd27f5f00116474fadcec5763f9e9b49",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ec7addb55a74073a8a13d754908cff3",
            "value": 1
          }
        },
        "bd27f5f00116474fadcec5763f9e9b49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb9da3a615334a0b8eec53b9df59ae95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb59187e04ad42b59180a87cd35b2c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
