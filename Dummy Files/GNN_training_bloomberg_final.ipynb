{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb1135304dd24bfca6bf4c88510e9f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_639fedaa4ca84b53a97d56892dc9d6be",
              "IPY_MODEL_41d7f86a405c4da689018e68d6ed1f7c"
            ],
            "layout": "IPY_MODEL_1457cca7ce2e4bb5975415a1f50eb4e9"
          }
        },
        "639fedaa4ca84b53a97d56892dc9d6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64a8c5ee7d1c45d5a860b90cd7a555ac",
            "placeholder": "​",
            "style": "IPY_MODEL_d5cb8fa0065e4b6c82149cee0189fb91",
            "value": "5.537 MB of 5.549 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "41d7f86a405c4da689018e68d6ed1f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4207a72bb28746a5b33332fd05e21f4d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_710cde3085e9409aa21337c430434a0a",
            "value": 0.9978608783770313
          }
        },
        "1457cca7ce2e4bb5975415a1f50eb4e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a8c5ee7d1c45d5a860b90cd7a555ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5cb8fa0065e4b6c82149cee0189fb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4207a72bb28746a5b33332fd05e21f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710cde3085e9409aa21337c430434a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb torch_geometric\n",
        "!pip install --upgrade gdown"
      ],
      "metadata": {
        "id": "uT_yIbUH46eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the four parts of the datasets in case of using the notebook from a different google drive\n",
        "# import gdown\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/1-JkyT8aKr9-eC2Pkof6D_qJdASYAXpUj?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/1-qmcIKbazhHGkb8gRFAjHxDzi0Jv33T-?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/106k3sK6wrcDzE_6ewGSUKqVD4nXlrIPE?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/10HjEkProRtYt5ROzamS7SY94JVuuBOxy?usp=sharing\")"
      ],
      "metadata": {
        "id": "P3pzd4QB2XGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"./drive\")"
      ],
      "metadata": {
        "id": "qEXNojNgaPze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d8d5db-2139-40a4-9afe-176c44f91b9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\"\"\"\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html\n",
        "\"\"\"\n",
        "from torch_geometric.data  import InMemoryDataset\n",
        "\n",
        "class WeekGraphs(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        super().__init__(root, transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'data.pt'\n",
        "\n",
        "    def process(self):\n",
        "        torch.save(self.collate(self.data_list), self.processed_paths[0])\n",
        "# dataset = WeekGraphs(\"/content/drive/MyDrive/Stock Market Prediction Graduation Project/graph_dataset_1st_year\", week_graphs)\n"
      ],
      "metadata": {
        "id": "9AJZuhDpZnRa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_points = []\n",
        "for i in range(1,4):\n",
        "  dataset = WeekGraphs(f\"./drive/MyDrive/bloomberg_graph_{i}\")\n",
        "  for k in range(len(dataset)):\n",
        "    all_points.append(dataset[k])"
      ],
      "metadata": {
        "id": "tqD5EKmOc_Fq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "file_path_in_run username/project/run_id\n",
        "\"\"\"\n",
        "\n",
        "def restore_file_wandb(file_path:str, run_name:str):\n",
        "    if not os.path.exists(\"/\".join(file_path.split(\"/\")[:-1])):\n",
        "        os.makedirs(\"/\".join(file_path.split(\"/\")[:-1]))\n",
        "    wandb.restore(file_path, run_path=run_name)"
      ],
      "metadata": {
        "id": "7iQ1oOmvMYCs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import (\n",
        "    add_self_loops,\n",
        "    negative_sampling,\n",
        "    remove_self_loops ,\n",
        ")\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score,average_precision_score\n",
        "from sklearn.metrics import precision_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "# import networkx as nx\n",
        "from typing import List , Dict,Tuple\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_geometric.nn as  gnn\n",
        "from torch_geometric.data  import Data\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "from torch.optim.adamw import AdamW\n",
        "import time\n",
        "from argparse import ArgumentParser\n",
        "import argparse\n",
        "import wandb\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "generator = torch.manual_seed(232)\n",
        "np.random.seed(232)\n",
        "torch.cuda.manual_seed(232)\n",
        "torch.cuda.manual_seed_all(232)\n",
        "random.seed(232)\n"
      ],
      "metadata": {
        "id": "KaLyYJ43zyA0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, num_layers=2,hidden_size=64, output_size=64, num_steps =15 ):\n",
        "        super().__init__()\n",
        "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        # self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(num_steps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # h0 = torch.zeros(2, x.size(0), 100).to(device) # num_layers * num_directions, batch_size, hidden_size\n",
        "        # c0 = torch.zeros(2, x.size(0), 100).to(device)\n",
        "        x = self.batch_norm1(x)\n",
        "        out, _ = self.lstm1(x)\n",
        "        # out, _ = self.lstm2(out)\n",
        "        out = F.relu(self.fc1(out[:, -1, :]))\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "6UdRLRRgnUab"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GConv(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim:int=64, num_layers:int=2, encode:bool=False, concat_out:bool=False, device='cpu', dropout=0.2):\n",
        "\n",
        "        super(GConv,self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.gconv_layers = []\n",
        "        self.norm_layers = []\n",
        "        self.encode = encode\n",
        "        for _ in range(num_layers):\n",
        "            self.gconv_layers.append(gnn.TransformerConv(emb_dim, emb_dim, heads=2, concat=False, dropout=dropout, add_self_loops = True).to(device)) # project=True ()\n",
        "            if self.encode:\n",
        "                self.norm_layers.append(nn.LayerNorm(emb_dim).to(device))\n",
        "        self.gconv_layers = nn.ModuleList(self.gconv_layers)\n",
        "        self.norm_layers = nn.ModuleList(self.norm_layers)\n",
        "\n",
        "        self.concat_out = concat_out\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "\n",
        "        outs = []\n",
        "        if self.encode:\n",
        "            outs.append(self.norm_layers[0](self.gconv_layers[0](x, edge_index)))\n",
        "        else:\n",
        "            outs.append(self.gconv_layers[0](x, edge_index))\n",
        "        for i in range(1,self.num_layers):\n",
        "            if self.encode:\n",
        "                outs.append(self.norm_layers[i](self.gconv_layers[i](outs[-1], edge_index)))\n",
        "            else:\n",
        "                outs.append(self.gconv_layers[i](outs[-1], edge_index))\n",
        "        if self.concat_out:\n",
        "            return torch.cat(outs, dim = -1)\n",
        "\n",
        "        return outs[-1]\n",
        "\n",
        "\n",
        "\n",
        "class NeuroStock(nn.Module):\n",
        "\n",
        "  def __init__(self,\n",
        "               num_timeseries_features=1,\n",
        "               n_companies=617,\n",
        "               company_emb_size=32,\n",
        "               node_emb_size=64,\n",
        "               article_emb_size=768,\n",
        "               n_industries=14,\n",
        "               n_gnn_layers=3,\n",
        "               use_timeseries_only=False,\n",
        "               graph_metadata:Tuple=None):\n",
        "    super(NeuroStock, self).__init__()\n",
        "    \"\"\"\n",
        "    company node representation will be a sum of its embedding and the output of the timeseries model (in this case it's an LSTM)\n",
        "    \"\"\"\n",
        "    self.num_timeseries_features = num_timeseries_features\n",
        "    self.n_companies = n_companies\n",
        "    self.company_emb_size = company_emb_size\n",
        "    self.node_emb_size = node_emb_size\n",
        "    self.article_emb_size = article_emb_size\n",
        "    self.n_industries = n_industries\n",
        "    self.n_gnn_layers = n_gnn_layers\n",
        "    self.use_timeseries_only = use_timeseries_only\n",
        "    self.lstm = LSTM(input_size=num_timeseries_features,  hidden_size=company_emb_size, output_size=company_emb_size).to(torch.float)\n",
        "\n",
        "    if graph_metadata is None:\n",
        "      raise(\"You need to pass HeteroData.metadata()\")\n",
        "    self.company_embedding = nn.Embedding(n_companies, company_emb_size).to(torch.float)\n",
        "    self.industry_embedding = nn.Embedding(n_industries, node_emb_size).to(torch.float)\n",
        "    self.project_article = nn.Linear(article_emb_size, node_emb_size).to(torch.float)\n",
        "\n",
        "    # to_hetero transforms normal gnn aggregation layer to a heterogeneous aggregation layer\n",
        "    # https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_transformer.to_hetero\n",
        "    self.g_conv = gnn.to_hetero(GConv(emb_dim=node_emb_size, num_layers=n_gnn_layers), graph_metadata).to(torch.float)\n",
        "    self.classifier = nn.Linear(node_emb_size, 2).to(torch.float)\n",
        "\n",
        "  def forward(self, hetero_x:HeteroData):\n",
        "    companies_timeseries = self.lstm(hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.float))\n",
        "    if self.use_timeseries_only:\n",
        "      out = self.classifier(companies_timeseries)\n",
        "      return out\n",
        "    hetero_x[\"sentence\"].x = self.project_article(hetero_x[\"sentence\"].x.to(torch.float))\n",
        "    companies = self.company_embedding(hetero_x[\"company\"].x)\n",
        "    # print(hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.double).shape, hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.float).dtype)\n",
        "    # company_timeseries is of shape (n_companies*batch_size, n_days, n_features)  the features are \"open\", \"high\", \"low\", \"close\", \"volume\"\n",
        "    hetero_x[\"company\"].x = companies_timeseries + companies  #companies are in shape (n_companies*batch_size, node_emb_size)\n",
        "\n",
        "    for k in hetero_x.edge_index_dict.keys():\n",
        "      hetero_x[k].edge_index = hetero_x[k].edge_index.to(torch.int64)\n",
        "    graph = self.g_conv(hetero_x.x_dict, hetero_x.edge_index_dict)\n",
        "    out = self.classifier(graph[\"company\"])\n",
        "    return out\n",
        "\n",
        "  def compute_loss(self, out, target):\n",
        "    loss = F.cross_entropy(out, target)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def get_output(neurostock:NeuroStock, points:List[HeteroData]):\n",
        "  data_loader = DataLoader(\n",
        "                points,\n",
        "                batch_size=1, shuffle=False)\n",
        "  neurostock.eval()\n",
        "  valid_losses = []\n",
        "  # continue\n",
        "  valid_outs = []\n",
        "  valid_targets = []\n",
        "  with torch.no_grad():\n",
        "      for i, batch  in enumerate(data_loader):\n",
        "        # if i > 2: break\n",
        "        batch = batch.to(device)\n",
        "        out = neurostock(batch)\n",
        "        # print(out.squeeze(-1).unsqueeze(0))\n",
        "        # print(batch[\"target\"].shape)\n",
        "        # break\n",
        "        valid_outs.append(out.unsqueeze(0).cpu().detach())\n",
        "        valid_targets.append(batch[\"target\"].unsqueeze(0).cpu().detach())\n",
        "        loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "        valid_losses.append(loss.item())\n",
        "  valid_outs = torch.cat(valid_outs).numpy()\n",
        "  valid_targets = torch.cat(valid_targets).numpy()\n",
        "  return valid_outs, valid_targets"
      ],
      "metadata": {
        "id": "zsGbydSFnH0b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.init(project=\"bloomberg_graph\", name=\"test_lstm\", config=train_config)\n",
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"]=\"4d60aa176a9e71fedbbaddb7ea594784ac8cc1ad\""
      ],
      "metadata": {
        "id": "2WrZxQwMPG5f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "J_FEnddZRyPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379ab552-6854-4c6b-8308-513d4d6e77e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmirette-gp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_config = {\n",
        "  \"n_epochs\" : 10,\n",
        "  \"step_size\" : 10,\n",
        "  \"node_emb_size\" : 128,\n",
        "  \"lr\" : 0.0001,\n",
        "  \"weight_decay\" : 0.01,\n",
        "  \"step_size\" : 10,\n",
        "  \"start_day\" : 500,\n",
        "  \"train_size\" : 300,\n",
        "  \"n_epochs\" : 10,\n",
        "  \"test_interval\" : 400,\n",
        "  \"train_batch_size\": 4,\n",
        "  \"use_timeseries_only\": True,\n",
        "  \"reset_parameters\" : False,\n",
        "  \"reset_parameters_freq\" : 5,\n",
        "  \"highest_conf_k\" : 100,\n",
        "  \"model_file_name\" : \"./neurostock_lstm.pt\",\n",
        "  \"run_name\" : \"lstm_fix_high_conf\",\n",
        "  \"project_name\":  \"bloomberg_graph\",\n",
        "}\n",
        "wandb.finish()\n",
        "wandb.init(project=train_config[\"project_name\"], name=train_config[\"run_name\"], config=train_config)\n",
        "# warmup_steps=\n",
        "neurostock = NeuroStock(\n",
        "    node_emb_size=train_config[\"node_emb_size\"],\n",
        "    company_emb_size=train_config[\"node_emb_size\"],\n",
        "    use_timeseries_only=train_config[\"use_timeseries_only\"],\n",
        "    graph_metadata=all_points[0].metadata())\n",
        "\n",
        "neurostock.to('cuda')\n",
        "device = next(neurostock.parameters()).device\n",
        "optimizer =  torch.optim.AdamW(neurostock.parameters(), lr=train_config[\"lr\"], weight_decay=train_config[\"weight_decay\"] )\n",
        "accs = []\n",
        "accum_companies = []\n",
        "high_conf_avgs = []\n",
        "# lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1,  total_iters=warmup_steps)\n",
        "for split_index, split in enumerate(range(0, train_config[\"test_interval\"], train_config[\"step_size\"])):\n",
        "\n",
        "  if train_config[\"reset_parameters\"] and (split_index + 1) % train_config[\"reset_parameters_freq\"]  == 0 :\n",
        "    for layer in neurostock.children():\n",
        "      if hasattr(layer, 'reset_parameters'):\n",
        "          layer.reset_parameters()\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "      all_points[train_config[\"start_day\"]+split:train_config[\"start_day\"]+split+train_config[\"train_size\"]],\n",
        "      batch_size=train_config[\"train_batch_size\"], shuffle=True)\n",
        "  test_loader = DataLoader(\n",
        "      all_points[train_config[\"start_day\"]+split+train_config[\"train_size\"]:train_config[\"start_day\"]+split+train_config[\"train_size\"]+train_config[\"step_size\"]],\n",
        "      batch_size=1, shuffle=False)\n",
        "\n",
        "  for e in tqdm(range(train_config[\"n_epochs\"])):\n",
        "      train_losses= []\n",
        "      neurostock.train()\n",
        "      train_outs = []\n",
        "      train_targets = []\n",
        "      for batch  in train_loader:\n",
        "          # with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "          batch = batch.to(device)\n",
        "          out = neurostock(batch)\n",
        "          train_outs.append(out.cpu().detach().unsqueeze(0))\n",
        "          train_targets.append(batch[\"target\"].cpu().detach().unsqueeze(0))\n",
        "          loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "          optimizer.zero_grad()\n",
        "          train_losses.append(loss.item())\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          # lr_scheduler.step()\n",
        "\n",
        "      neurostock.eval()\n",
        "      valid_losses = []\n",
        "      # continue\n",
        "      valid_outs = []\n",
        "      valid_targets = []\n",
        "      with torch.no_grad():\n",
        "\n",
        "          for i, batch  in enumerate(test_loader):\n",
        "            # if i > 2: break\n",
        "\n",
        "            batch = batch.to(device)\n",
        "            out = neurostock(batch)\n",
        "            valid_outs.append(out.cpu().detach().unsqueeze(0))\n",
        "            valid_targets.append(batch[\"target\"].cpu().detach().unsqueeze(0))\n",
        "            loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "      valid_outs = torch.cat(valid_outs).numpy()\n",
        "      valid_targets = torch.cat(valid_targets).numpy()\n",
        "      acc_per_company = (valid_outs.argmax(-1) == valid_targets).mean(axis=0)\n",
        "      high_acc_companies = np.where(acc_per_company >= 0.7)[0]\n",
        "\n",
        "      valid_acc = (valid_outs.argmax(-1) == valid_targets).mean()\n",
        "      train_outs = torch.cat(train_outs).numpy()\n",
        "      train_targets = torch.cat(train_targets).numpy()\n",
        "      train_acc = (train_outs.argmax(-1) == train_targets).mean()\n",
        "      # if e == (n_epochs- 1) :\n",
        "  high_confidence_accs = []\n",
        "  for out, target in zip(valid_outs, valid_targets):\n",
        "    predicted_label = out.argmax(-1)\n",
        "    confidence = out.max(-1)\n",
        "    predicted_label = predicted_label[confidence.argsort()[-train_config[\"highest_conf_k\"]:]]\n",
        "    target = target[confidence.argsort()[-train_config[\"highest_conf_k\"]:]]\n",
        "    high_confidence_accs.append((target ==predicted_label).mean())\n",
        "  high_conf_avgs.append(sum(high_confidence_accs)/len(high_confidence_accs))\n",
        "\n",
        "  wandb.log({\n",
        "          \"train_loss\" : np.mean(train_losses),\n",
        "          \"valid_loss\" : np.mean(valid_losses),\n",
        "          \"valid_acc\" : valid_acc,\n",
        "          \"high_confidence_acc\" : sum(high_confidence_accs)/len(high_confidence_accs),\n",
        "          \"valid_n_high\" : (acc_per_company >= 0.7).sum(),\n",
        "          \"train_acc\" : train_acc\n",
        "    })\n",
        "  accs.append(valid_acc)\n",
        "  # wandb.log({\"avg_acc\": np.mean(valid_acc)})\n",
        "  accum_companies.append(high_acc_companies)\n",
        "# wandb.finish()\n",
        "\n",
        "long_range_outputs, long_range_true = get_output(neurostock, all_points[train_config[\"start_day\"]+split+train_config[\"train_size\"]+train_config[\"step_size\"]:])\n",
        "\n",
        "all_high = []\n",
        "for k in  accum_companies:\n",
        "  all_high.extend(k)\n",
        "\n",
        "torch.save(neurostock, train_config[\"model_file_name\"])\n",
        "wandb.save(train_config[\"model_file_name\"])\n",
        "\n",
        "\n",
        "wandb.log({\"avg_acc\": np.mean(accs),\n",
        "           \"high_conf_avgs\" : np.mean(high_conf_avgs),\n",
        "           \"higher_0.7_mean\": np.mean([len(h) for h in accum_companies]),\n",
        "           \"higher_0.7_std\": np.std([len(h) for h in accum_companies]),\n",
        "           \"avg_high_company_occurrence\": np.mean(pd.Series(all_high).value_counts()[:train_config[\"highest_conf_k\"]].values),\n",
        "           \"long_range_acc\" : (long_range_outputs.argmax(-1) == long_range_true).mean()\n",
        "           })\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eb1135304dd24bfca6bf4c88510e9f13",
            "639fedaa4ca84b53a97d56892dc9d6be",
            "41d7f86a405c4da689018e68d6ed1f7c",
            "1457cca7ce2e4bb5975415a1f50eb4e9",
            "64a8c5ee7d1c45d5a860b90cd7a555ac",
            "d5cb8fa0065e4b6c82149cee0189fb91",
            "4207a72bb28746a5b33332fd05e21f4d",
            "710cde3085e9409aa21337c430434a0a"
          ]
        },
        "id": "XaJSUav3rFxI",
        "outputId": "e722108e-0465-40e6-b116-50b97a1cba7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmirette-gp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230623_135858-6dsvbqqd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/6dsvbqqd' target=\"_blank\">lstm_fix_high_conf</a></strong> to <a href='https://wandb.ai/mirette-gp/bloomberg_graph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mirette-gp/bloomberg_graph' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/6dsvbqqd' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph/runs/6dsvbqqd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:32<00:00,  3.27s/it]\n",
            "100%|██████████| 10/10 [00:30<00:00,  3.03s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.19s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.14s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.17s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.18s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.19s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.17s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.15s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.18s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.17s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.17s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.17s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.18s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
            "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='5.537 MB of 5.537 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb1135304dd24bfca6bf4c88510e9f13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_acc</td><td>▁</td></tr><tr><td>avg_high_company_occurrence</td><td>▁</td></tr><tr><td>high_conf_avgs</td><td>▁</td></tr><tr><td>high_confidence_acc</td><td>▂▅▆▂▇▇▅█▆▄▅▅▄▃▄▅▃▃▅▆▆▃▁▅▂▂▄▅▃▅▄▃▄▄▅▄▂▄▃▁</td></tr><tr><td>higher_0.7_mean</td><td>▁</td></tr><tr><td>higher_0.7_std</td><td>▁</td></tr><tr><td>long_range_acc</td><td>▁</td></tr><tr><td>train_acc</td><td>▇▆▆▇▆▆▇▇▇▇█▇▇▇▇▆▆▆▅▄▄▄▄▃▄▄▃▃▂▂▃▃▂▁▂▂▁▂▃▄</td></tr><tr><td>train_loss</td><td>▃▄▄▄▄▄▃▃▂▂▁▂▂▂▃▅▄▅▆▆▆▇▇▇▆▇▇███▇▇██████▇▆</td></tr><tr><td>valid_acc</td><td>▃▄▅▃▅▇▃█▅▅▄▄▆▂▄▄▃▄▄▆▆▂▁▄▃▂▃▄▂▄▄▂▁▅▆▄▁▄▃▂</td></tr><tr><td>valid_loss</td><td>▇▆▅▇▄▃▇▁▄▅▆▆▃█▆▆▇▅▅▄▄▇▇▅▆▇▆▅▆▅▆▆▆▅▅▆▆▅▆▇</td></tr><tr><td>valid_n_high</td><td>▂▂▄▁▄▅▂█▄▃▂▂▄▁▃▂▂▃▃▅▄▁▁▂▂▁▂▃▂▄▂▁▁▄▅▂▁▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_acc</td><td>0.50022</td></tr><tr><td>avg_high_company_occurrence</td><td>13.67</td></tr><tr><td>high_conf_avgs</td><td>0.5382</td></tr><tr><td>high_confidence_acc</td><td>0.417</td></tr><tr><td>higher_0.7_mean</td><td>100.275</td></tr><tr><td>higher_0.7_std</td><td>51.01813</td></tr><tr><td>long_range_acc</td><td>0.5229</td></tr><tr><td>train_acc</td><td>0.51085</td></tr><tr><td>train_loss</td><td>0.69283</td></tr><tr><td>valid_acc</td><td>0.44838</td></tr><tr><td>valid_loss</td><td>0.69661</td></tr><tr><td>valid_n_high</td><td>46</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lstm_fix_high_conf</strong> at: <a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/6dsvbqqd' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph/runs/6dsvbqqd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230623_135858-6dsvbqqd/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(neurostock, \"./neurostock_gnn.pt\")\n",
        "# wandb.save(\"./neurostock_gnn.pt\")\n",
        "# wandb.init(\"bloomberg_model\", name=\"tranformer_conv\")\n",
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "UMTX2ko7PHbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_acc_per_company  = (valid_outs.argmax(-1) == valid_targets).mean(0)\n",
        "pd.Series(test_acc_per_company).hist(), test_acc_per_company.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "f5SRqaEkAqM3",
        "outputId": "d6ad4d36-1b12-4085-db94-31d3a2a8caf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Axes: >, 0.5173240938166311)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}