{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cff9b43d4aa844a0b08b65b714a39750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54f5ba5db65b4f8b98c3849006a7d0f4",
              "IPY_MODEL_d8ae1f67fd9b4da79b48c62f0b87fd34"
            ],
            "layout": "IPY_MODEL_b80303070a5a4956a6e4a942b4498192"
          }
        },
        "54f5ba5db65b4f8b98c3849006a7d0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89b162642fc4ec495f83dd9b4e42494",
            "placeholder": "​",
            "style": "IPY_MODEL_4c4ff470a4604685bfdd6c208ea5f231",
            "value": "0.012 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "d8ae1f67fd9b4da79b48c62f0b87fd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7901791b1d1845978bc6b7829a98e892",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9705579742c41ebb7766318f48872b3",
            "value": 0.970107672615014
          }
        },
        "b80303070a5a4956a6e4a942b4498192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89b162642fc4ec495f83dd9b4e42494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4ff470a4604685bfdd6c208ea5f231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7901791b1d1845978bc6b7829a98e892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9705579742c41ebb7766318f48872b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb torch_geometric\n",
        "!pip install --upgrade gdown"
      ],
      "metadata": {
        "id": "uT_yIbUH46eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the four parts of the datasets in case of using the notebook from a different google drive\n",
        "# import gdown\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/1-JkyT8aKr9-eC2Pkof6D_qJdASYAXpUj?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/1-qmcIKbazhHGkb8gRFAjHxDzi0Jv33T-?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/106k3sK6wrcDzE_6ewGSUKqVD4nXlrIPE?usp=sharing\")\n",
        "# gdown.download_folder(\"https://drive.google.com/drive/folders/10HjEkProRtYt5ROzamS7SY94JVuuBOxy?usp=sharing\")"
      ],
      "metadata": {
        "id": "P3pzd4QB2XGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"./drive\")"
      ],
      "metadata": {
        "id": "qEXNojNgaPze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebcf5ac-5d82-428a-e1fd-b02ec3b406fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\"\"\"\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html\n",
        "\"\"\"\n",
        "from torch_geometric.data  import InMemoryDataset\n",
        "\n",
        "class WeekGraphs(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        super().__init__(root, transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'data.pt'\n",
        "\n",
        "    def process(self):\n",
        "        torch.save(self.collate(self.data_list), self.processed_paths[0])\n",
        "# dataset = WeekGraphs(\"/content/drive/MyDrive/Stock Market Prediction Graduation Project/graph_dataset_1st_year\", week_graphs)\n"
      ],
      "metadata": {
        "id": "9AJZuhDpZnRa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_points = []\n",
        "for i in range(1,4):\n",
        "  dataset = WeekGraphs(f\"./drive/MyDrive/bloomberg_graph_{i}\")\n",
        "  for k in range(len(dataset)):\n",
        "    all_points.append(dataset[k])"
      ],
      "metadata": {
        "id": "tqD5EKmOc_Fq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "\"\"\"\n",
        "file_path_in_run username/project/run_id\n",
        "\"\"\"\n",
        "\n",
        "def restore_file_wandb(file_path:str, run_name:str):\n",
        "    if not os.path.exists(\"/\".join(file_path.split(\"/\")[:-1])):\n",
        "        os.makedirs(\"/\".join(file_path.split(\"/\")[:-1]))\n",
        "    wandb.restore(file_path, run_path=run_name)"
      ],
      "metadata": {
        "id": "7iQ1oOmvMYCs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import (\n",
        "    add_self_loops,\n",
        "    negative_sampling,\n",
        "    remove_self_loops ,\n",
        ")\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score,average_precision_score\n",
        "from sklearn.metrics import precision_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "# import networkx as nx\n",
        "from typing import List , Dict,Tuple\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_geometric.nn as  gnn\n",
        "from torch_geometric.data  import Data\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "from torch.optim.adamw import AdamW\n",
        "import time\n",
        "from argparse import ArgumentParser\n",
        "import argparse\n",
        "import wandb\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "generator = torch.manual_seed(232)\n",
        "np.random.seed(232)\n",
        "torch.cuda.manual_seed(232)\n",
        "torch.cuda.manual_seed_all(232)\n",
        "random.seed(232)\n"
      ],
      "metadata": {
        "id": "KaLyYJ43zyA0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, num_layers=2,hidden_size=64, output_size=64, num_steps =15 ):\n",
        "        super().__init__()\n",
        "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        # self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(num_steps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # h0 = torch.zeros(2, x.size(0), 100).to(device) # num_layers * num_directions, batch_size, hidden_size\n",
        "        # c0 = torch.zeros(2, x.size(0), 100).to(device)\n",
        "        x = self.batch_norm1(x)\n",
        "        out, _ = self.lstm1(x)\n",
        "        # out, _ = self.lstm2(out)\n",
        "        out = F.relu(self.fc1(out[:, -1, :]))\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "6UdRLRRgnUab"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.int64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaEMxSI50ttx",
        "outputId": "a3928a96-f8cc-4ad8-8f3d-a36d920a81ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GConv(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim:int=64, num_layers:int=2, encode:bool=False, concat_out:bool=False, device='cpu', dropout=0.2):\n",
        "\n",
        "        super(GConv,self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.gconv_layers = []\n",
        "        self.norm_layers = []\n",
        "        self.encode = encode\n",
        "        for _ in range(num_layers):\n",
        "            self.gconv_layers.append(gnn.TransformerConv(emb_dim, emb_dim, heads=2, concat=False, dropout=dropout, add_self_loops = True).to(device)) # project=True ()\n",
        "            if self.encode:\n",
        "                self.norm_layers.append(nn.LayerNorm(emb_dim).to(device))\n",
        "        self.gconv_layers = nn.ModuleList(self.gconv_layers)\n",
        "        self.norm_layers = nn.ModuleList(self.norm_layers)\n",
        "\n",
        "        self.concat_out = concat_out\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "\n",
        "        outs = []\n",
        "        if self.encode:\n",
        "            outs.append(self.norm_layers[0](self.gconv_layers[0](x, edge_index)))\n",
        "        else:\n",
        "            outs.append(self.gconv_layers[0](x, edge_index))\n",
        "        for i in range(1,self.num_layers):\n",
        "            if self.encode:\n",
        "                outs.append(self.norm_layers[i](self.gconv_layers[i](outs[-1], edge_index)))\n",
        "            else:\n",
        "                outs.append(self.gconv_layers[i](outs[-1], edge_index))\n",
        "        if self.concat_out:\n",
        "            return torch.cat(outs, dim = -1)\n",
        "\n",
        "        return outs[-1]\n",
        "\n",
        "\n",
        "\n",
        "class NeuroStock(nn.Module):\n",
        "\n",
        "  def __init__(self,\n",
        "               num_timeseries_features=1,\n",
        "               n_companies=617,\n",
        "               company_emb_size=32,\n",
        "               node_emb_size=64,\n",
        "               article_emb_size=768,\n",
        "               n_industries=14,\n",
        "               n_gnn_layers=3,\n",
        "               use_timeseries_only=False,\n",
        "               graph_metadata:Tuple=None):\n",
        "    super(NeuroStock, self).__init__()\n",
        "    \"\"\"\n",
        "    company node representation will be a concatenation of its embedding and the output of the timeseries model (in this case it's an LSTM)\n",
        "    \"\"\"\n",
        "    self.num_timeseries_features = num_timeseries_features\n",
        "    self.n_companies = n_companies\n",
        "    self.company_emb_size = company_emb_size\n",
        "    self.node_emb_size = node_emb_size\n",
        "    self.article_emb_size = article_emb_size\n",
        "    self.n_industries = n_industries\n",
        "    self.n_gnn_layers = n_gnn_layers\n",
        "    self.use_timeseries_only = use_timeseries_only\n",
        "    self.lstm = LSTM(input_size=num_timeseries_features,  hidden_size=company_emb_size, output_size=company_emb_size).to(torch.float)\n",
        "\n",
        "    if graph_metadata is None:\n",
        "      raise(\"You need to pass HeteroData.metadata()\")\n",
        "    self.company_embedding = nn.Embedding(n_companies, company_emb_size).to(torch.float)\n",
        "    self.industry_embedding = nn.Embedding(n_industries, node_emb_size).to(torch.float)\n",
        "    self.project_article = nn.Linear(article_emb_size, node_emb_size).to(torch.float)\n",
        "\n",
        "    # to_hetero transforms normal gnn aggregation layer to a heterogeneous aggregation layer\n",
        "    # https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_transformer.to_hetero\n",
        "    self.g_conv = gnn.to_hetero(GConv(emb_dim=node_emb_size, num_layers=n_gnn_layers), graph_metadata).to(torch.float)\n",
        "    self.classifier = nn.Linear(node_emb_size, 2).to(torch.float)\n",
        "\n",
        "  def forward(self, hetero_x:HeteroData):\n",
        "    companies_timeseries = self.lstm(hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.float))\n",
        "    if self.use_timeseries_only:\n",
        "      out = self.classifier(companies_timeseries)\n",
        "      return out\n",
        "    hetero_x[\"sentence\"].x = self.project_article(hetero_x[\"sentence\"].x.to(torch.float))\n",
        "    companies = self.company_embedding(hetero_x[\"company\"].x)\n",
        "    # print(hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.double).shape, hetero_x[\"company_timeseries\"][:,:, -2:-1].to(torch.float).dtype)\n",
        "    # company_timeseries is of shape (n_companies*batch_size, n_days, n_features)  the features are \"open\", \"high\", \"low\", \"close\", \"volume\"\n",
        "    hetero_x[\"company\"].x = companies_timeseries + companies  #companies are in shape (n_companies*batch_size, node_emb_size)\n",
        "\n",
        "    for k in hetero_x.edge_index_dict.keys():\n",
        "      hetero_x[k].edge_index = hetero_x[k].edge_index.to(torch.int64)\n",
        "    graph = self.g_conv(hetero_x.x_dict, hetero_x.edge_index_dict)\n",
        "    out = self.classifier(graph[\"company\"])\n",
        "    return out\n",
        "\n",
        "  def compute_loss(self, out, target):\n",
        "    loss = F.cross_entropy(out, target)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "zsGbydSFnH0b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.init(project=\"bloomberg_graph\", name=\"test_lstm\", config=train_config)\n",
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"]=\"4d60aa176a9e71fedbbaddb7ea594784ac8cc1ad\""
      ],
      "metadata": {
        "id": "2WrZxQwMPG5f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export WANDB_API_KEY=4d60aa176a9e71fedbbaddb7ea594784ac8cc1ad"
      ],
      "metadata": {
        "id": "j7ROsnwxRCWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "J_FEnddZRyPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd45bee-3cc7-4464-830d-9b8ac70fa3cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmirette-gp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_config = {\n",
        "  \"n_epochs\" : 10,\n",
        "  \"step_size\" : 10,\n",
        "  \"node_emb_size\" : 128,\n",
        "  \"lr\" : 0.0001,\n",
        "  \"weight_decay\" : 0.01,\n",
        "  \"step_size\" : 10,\n",
        "  \"start_day\" : 500,\n",
        "  \"train_size\" : 200,\n",
        "  \"n_epochs\" : 10,\n",
        "  \"test_interval\" : 400,\n",
        "  \"train_batch_size\": 2,\n",
        "  \"use_timeseries_only\": False,\n",
        "  \"reset_parameters\" : True,\n",
        "  \"reset_parameters_freq\" : 5,\n",
        "}\n",
        "wandb.init(project=\"bloomberg_graph\", name=\"test_transformer_conv_reset_parameters\", config=train_config)\n",
        "# warmup_steps=\n",
        "neurostock = NeuroStock(\n",
        "    node_emb_size=train_config[\"node_emb_size\"],\n",
        "    company_emb_size=train_config[\"node_emb_size\"],\n",
        "    use_timeseries_only=train_config[\"use_timeseries_only\"],\n",
        "    graph_metadata=all_points[0].metadata())\n",
        "\n",
        "neurostock.to('cuda')\n",
        "device = next(neurostock.parameters()).device\n",
        "optimizer =  torch.optim.AdamW(neurostock.parameters(), lr=train_config[\"lr\"], weight_decay=train_config[\"weight_decay\"] )\n",
        "accs = []\n",
        "accum_companies = []\n",
        "\n",
        "# lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1,  total_iters=warmup_steps)\n",
        "for split_index, split in enumerate(range(0, train_config[\"test_interval\"], train_config[\"step_size\"])):\n",
        "\n",
        "  if train_config[\"reset_parameters\"] and (split_index + 1) % train_config[\"reset_parameters_freq\"]  == 0 :\n",
        "    for layer in neurostock.children():\n",
        "      if hasattr(layer, 'reset_parameters'):\n",
        "          layer.reset_parameters()\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "      all_points[train_config[\"start_day\"]+split:train_config[\"start_day\"]+split+train_config[\"train_size\"]],\n",
        "      batch_size=train_config[\"train_batch_size\"], shuffle=True)\n",
        "  test_loader = DataLoader(\n",
        "      all_points[train_config[\"start_day\"]+split+train_config[\"train_size\"]:train_config[\"start_day\"]+split+train_config[\"train_size\"]+train_config[\"step_size\"]],\n",
        "      batch_size=1, shuffle=False)\n",
        "\n",
        "  for e in tqdm(range(train_config[\"n_epochs\"])):\n",
        "      train_losses= []\n",
        "      neurostock.train()\n",
        "      train_outs = []\n",
        "      train_targets = []\n",
        "      for batch  in train_loader:\n",
        "          # with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "          batch = batch.to(device)\n",
        "          out = neurostock(batch)\n",
        "          train_outs.append(out.cpu().detach().unsqueeze(0))\n",
        "          train_targets.append(batch[\"target\"].cpu().detach().unsqueeze(0))\n",
        "          loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "          optimizer.zero_grad()\n",
        "          train_losses.append(loss.item())\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          # lr_scheduler.step()\n",
        "\n",
        "      neurostock.eval()\n",
        "      valid_losses = []\n",
        "      # continue\n",
        "      valid_outs = []\n",
        "      valid_targets = []\n",
        "      with torch.no_grad():\n",
        "\n",
        "          for i, batch  in enumerate(test_loader):\n",
        "            # if i > 2: break\n",
        "\n",
        "            batch = batch.to(device)\n",
        "            out = neurostock(batch)\n",
        "            valid_outs.append(out.cpu().detach().unsqueeze(0))\n",
        "            valid_targets.append(batch[\"target\"].cpu().detach().unsqueeze(0))\n",
        "            loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "      valid_outs = torch.cat(valid_outs).numpy()\n",
        "      valid_targets = torch.cat(valid_targets).numpy()\n",
        "      acc_per_company = (valid_outs.argmax(-1) == valid_targets).mean(axis=0)\n",
        "      high_acc_companies = np.where(acc_per_company >= 0.7)[0]\n",
        "\n",
        "      valid_acc = (valid_outs.argmax(-1) == valid_targets).mean()\n",
        "      train_outs = torch.cat(train_outs).numpy()\n",
        "      train_targets = torch.cat(train_targets).numpy()\n",
        "      train_acc = (train_outs.argmax(-1) == train_targets).mean()\n",
        "      # if e == (n_epochs- 1) :\n",
        "  wandb.log({\n",
        "          \"train_loss\" : np.mean(train_losses),\n",
        "          \"valid_loss\" : np.mean(valid_losses),\n",
        "          \"valid_acc\" : valid_acc,\n",
        "          \"valid_n_high\" : (acc_per_company >= 0.7).sum(),\n",
        "          \"train_acc\" : train_acc\n",
        "    })\n",
        "  accs.append(valid_acc)\n",
        "  # wandb.log({\"avg_acc\": np.mean(valid_acc)})\n",
        "  accum_companies.append(high_acc_companies)\n",
        "# wandb.finish()\n",
        "all_high = []\n",
        "for k in  accum_companies:\n",
        "  all_high.extend(k)\n",
        "\n",
        "\n",
        "\n",
        "wandb.log({\"avg_acc\": np.mean(accs),\n",
        "           \"higher_0.7_mean\": np.mean([len(h) for h in accum_companies]),\n",
        "           \"higher_0.7_std\": np.std([len(h) for h in accum_companies]),\n",
        "           \"avg_high_company_occurrence\": np.mean(pd.Series(all_high).value_counts()[:100].values)\n",
        "           })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "XaJSUav3rFxI",
        "outputId": "19709a26-0816-4f1f-c2ef-ae45817268fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmirette-gp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230623_095050-gdc2watt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/gdc2watt' target=\"_blank\">test_transformer_conv_reset_parameters</a></strong> to <a href='https://wandb.ai/mirette-gp/bloomberg_graph' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mirette-gp/bloomberg_graph' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/gdc2watt' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph/runs/gdc2watt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:41<00:00,  4.20s/it]\n",
            "100%|██████████| 10/10 [00:45<00:00,  4.57s/it]\n",
            "100%|██████████| 10/10 [00:42<00:00,  4.26s/it]\n",
            "100%|██████████| 10/10 [00:42<00:00,  4.27s/it]\n",
            "100%|██████████| 10/10 [00:43<00:00,  4.31s/it]\n",
            "100%|██████████| 10/10 [00:43<00:00,  4.31s/it]\n",
            "100%|██████████| 10/10 [00:43<00:00,  4.35s/it]\n",
            "100%|██████████| 10/10 [00:52<00:00,  5.29s/it]\n",
            "100%|██████████| 10/10 [00:48<00:00,  4.89s/it]\n",
            "100%|██████████| 10/10 [00:45<00:00,  4.57s/it]\n",
            " 10%|█         | 1/10 [00:04<00:38,  4.23s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730,
          "referenced_widgets": [
            "cff9b43d4aa844a0b08b65b714a39750",
            "54f5ba5db65b4f8b98c3849006a7d0f4",
            "d8ae1f67fd9b4da79b48c62f0b87fd34",
            "b80303070a5a4956a6e4a942b4498192",
            "a89b162642fc4ec495f83dd9b4e42494",
            "4c4ff470a4604685bfdd6c208ea5f231",
            "7901791b1d1845978bc6b7829a98e892",
            "b9705579742c41ebb7766318f48872b3"
          ]
        },
        "id": "-jKUilUcVuAC",
        "outputId": "f29c4354-1b08-48d1-8866-532daf25b04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.090580…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cff9b43d4aa844a0b08b65b714a39750"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_acc</td><td>▁</td></tr><tr><td>avg_high_company_occurrence</td><td>▁</td></tr><tr><td>higher_0.7_mean</td><td>▁</td></tr><tr><td>higher_0.7_std</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▇▇██▇██▇▇██▇▇▇███▇▇▇▇▇█▇███▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▆▄▃▂▂▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄</td></tr><tr><td>valid_acc</td><td>▇▆▄▄▅▆▅█▂▁▄▅▄▅▄▅▆▄▆▅▅▅▃▂▃▅▄▅▃▃▅▃▂▃▄▄▄▅▅▃</td></tr><tr><td>valid_loss</td><td>▂▂▂▂▂▁▂▁▄▆▄▃▃▃▃▃▃▃▂▃▃▄▅█▆▆▄▅▅▅▄▅▆▇▅▅▅▄▄▅</td></tr><tr><td>valid_n_high</td><td>▄▅▁▅▃▄▄█▃▄▄▅▄▅▄▅▅▅▆▄▄▅▄▃▃▅▄▄▄▄▅▄▄▂▅▄▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_acc</td><td>0.51865</td></tr><tr><td>avg_high_company_occurrence</td><td>15.38</td></tr><tr><td>higher_0.7_mean</td><td>117.125</td></tr><tr><td>higher_0.7_std</td><td>21.05254</td></tr><tr><td>train_acc</td><td>0.57567</td></tr><tr><td>train_loss</td><td>0.66146</td></tr><tr><td>valid_acc</td><td>0.50812</td></tr><tr><td>valid_loss</td><td>0.70705</td></tr><tr><td>valid_n_high</td><td>125</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">test_transformer_conv</strong> at: <a href='https://wandb.ai/mirette-gp/bloomberg_graph/runs/g50f3vzy' target=\"_blank\">https://wandb.ai/mirette-gp/bloomberg_graph/runs/g50f3vzy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230621_185110-g50f3vzy/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gets gets the mentions of every company\n",
        "company_mentions = []\n",
        "for p in range(500, len(all_points)):\n",
        "  company_mentions.extend(all_points[p][\"sentence\", \"mentioned\", \"company\"].edge_index[1].numpy().tolist())\n"
      ],
      "metadata": {
        "id": "QqjFY_CHD2k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_mentioned = pd.Series(company_mentions).value_counts().index"
      ],
      "metadata": {
        "id": "Fp-Lc4AFPZo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gets how frequent every company gets a 0.7 accuracy over 10 days\n",
        "all_high = []\n",
        "for k in  accum_companies:\n",
        "  all_high.extend(k)\n",
        "np.mean(pd.Series(all_high).value_counts()[:20].values) #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-yqv3_ES8ci",
        "outputId": "f80aac8b-f453-40e4-fd01-9ad1e928afeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.5"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len([k for k in pd.Series(accum_companies).value_counts()[:200].index if k in most_mentioned[:200]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgqXLADXGjN0",
        "outputId": "eb7ec147-26c6-4467-a094-a922be25ba5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(all_points[600+split+200+step_size:], batch_size=1, shuffle=False)\n",
        "neurostock.eval()\n",
        "valid_losses = []\n",
        "# continue\n",
        "valid_outs = []\n",
        "valid_targets = []\n",
        "with torch.no_grad():\n",
        "    for i, batch  in enumerate(test_loader):\n",
        "      # if i > 2: break\n",
        "      batch = batch.to(device)\n",
        "      out = neurostock(batch)\n",
        "      # print(out.squeeze(-1).unsqueeze(0))\n",
        "      # print(batch[\"target\"].shape)\n",
        "      # break\n",
        "      valid_outs.append(out.squeeze(-1).unsqueeze(0).cpu().detach())\n",
        "      valid_targets.append(batch[\"target\"].squeeze(-1).unsqueeze(0).cpu().detach())\n",
        "      loss = neurostock.compute_loss(out, batch[\"target\"])\n",
        "      valid_losses.append(loss.item())\n",
        "valid_outs = torch.cat(valid_outs).numpy()\n",
        "valid_targets = torch.cat(valid_targets).numpy()\n"
      ],
      "metadata": {
        "id": "_WrV26wD6CQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_acc_per_company  = ((valid_outs >= 0.5) == valid_targets).mean(0)\n",
        "pd.Series(test_acc_per_company).hist(), test_acc_per_company.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "f5SRqaEkAqM3",
        "outputId": "1fb74fd4-d613-4326-c05c-038dc3083add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Axes: >, 0.5249806163985268)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}